{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b1a2f8-2422-47a8-b3e2-eee2cacc5746",
   "metadata": {},
   "source": [
    "# Read files for the Mallee Woodlands\n",
    "\n",
    "This Excel workbook was prepared by Prof. David Keith, FAA, and imported on May 2023.\n",
    "\n",
    "We need to adapt functions defined in modules `fireveg` and `firevegdb`  to:\n",
    "\n",
    "- Read data from spreadsheets with field-work data\n",
    "- Create records for data import into the database\n",
    "- Insert or update records in the database\n",
    "\n",
    "For this dataset we have several sites (S2007/1, T2001/1, etc), each site has several subplots with different treatments (A, K, N, R, G, X1, X2, X3) and replicates for each site/subplot.\n",
    "\n",
    "This jupyter notebook runs through each step of data import, starting with field site and visit information. Then... other steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a04fac-d940-49e8-90cc-55b8a660f316",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set-up\n",
    "Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "049c8f14-e17d-4188-98c8-4477d94d8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "from psycopg2.extensions import AsIs\n",
    "import pyprojroot\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee583770-35a6-417b-afcb-37d5900f2ebe",
   "metadata": {},
   "source": [
    "Load functions from `lib` folder, we will use a function to read db credentials and one for batch insert and updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0132f0e1-6843-4ee3-b408-50de87e7324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.parseparams import read_dbparams\n",
    "from lib.firevegdb import batch_upsert\n",
    "from lib.firevegdb import validate_and_update_site_records\n",
    "\n",
    "import lib.fireveg as fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf68a87e-0fb6-4976-b0ba-0ab115de571d",
   "metadata": {},
   "source": [
    "Define path to workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70501e6-fbdf-4aae-a67f-b9fd30b75dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "repodir = pyprojroot.find_root(pyprojroot.has_dir(\".git\"))\n",
    "inputdir = repodir / \"data\" / \"input-field-form\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333fb8b-20ee-41ec-9be0-a9726356bdc3",
   "metadata": {},
   "source": [
    "Database credentials are stored in a database.ini file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51adc750-4ff8-4797-8d41-3ef8bc485a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbparams = read_dbparams(repodir / 'secrets' / 'database.ini', section='aws-lght-sl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63b16d9-5538-43b0-b0f2-c8e0c4199575",
   "metadata": {
    "tags": []
   },
   "source": [
    "## List of workbooks/spreadsheets in directory\n",
    "\n",
    "Each spreadsheet has a slightly different structure, so these scripts have to be adapted for each case.\n",
    "\n",
    "We use functions from module `fireveg` to read the data and create records, and functions from module `firevegdb` to execute the SQL insert or update query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "729cc97e-b551-4059-9710-61b5a53cfcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx',\n",
       " 'PlantFireTraitData_2011-2018_Import_AdditionalSiteInfo.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx',\n",
       " 'SthnNSWRF_data_bionet2.xlsx',\n",
       " 'UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx',\n",
       " 'PlantFireTraitData_2011-2018_Import.xlsx',\n",
       " '.ipynb_checkpoints',\n",
       " 'UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx',\n",
       " 'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh.xlsx',\n",
       " 'UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx',\n",
       " 'RobertsonRF_data_bionet2.xlsx',\n",
       " 'Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6f7f38c-4f11-4054-b2f2-8e1309b3a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files =  ['PlantFireTraitData_2011-2018_Import.xlsx',\n",
    "             'PlantFireTraitData_2011-2018_Import_AdditionalSiteInfo.xlsx']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a42a0a2-9cd1-46a1-abcb-a5abb63b9584",
   "metadata": {},
   "source": [
    "Here we create an index of worksheets and column headers for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "629a0965-eae1-46fc-b49c-c858e6161b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbindex=dict()\n",
    "for workbook_name in valid_files:\n",
    "    inputfile=inputdir / workbook_name\n",
    "    # using data_only=True to get the calculated cell values\n",
    "    wb = openpyxl.load_workbook(inputfile,data_only=True)\n",
    "    wbindex[workbook_name]=dict()\n",
    "    for ws in wb.worksheets:\n",
    "        wbindex[workbook_name][ws._WorkbookChild__title]=list()\n",
    "        for k in range(1,ws.max_column):\n",
    "            wbindex[workbook_name][ws._WorkbookChild__title].append(ws.cell(row=1,column=k).value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741e415-b034-4d81-ba5e-8e9d10b5d814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Database queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336797-28e5-49d0-a3b3-8717acbbbb28",
   "metadata": {},
   "source": [
    "Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68b6db1e-51ab-49cf-9f97-c4a9bf12df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n"
     ]
    }
   ],
   "source": [
    "# connect to the PostgreSQL server\n",
    "print('Connecting to the PostgreSQL database...')\n",
    "conn = psycopg2.connect(**dbparams)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0245c2-fdfe-473f-955f-d34099e29788",
   "metadata": {},
   "source": [
    "### create new survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19eabe83-14d7-40af-91c4-9720aefd5958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSERT INTO form.surveys(survey_name) values ('Mallee Woodlands') ON CONFLICT DO NOTHING;\n",
      "0 rows updated\n"
     ]
    }
   ],
   "source": [
    "updated_rows = 0\n",
    "qry = \"INSERT INTO form.surveys(survey_name) values ('Mallee Woodlands') ON CONFLICT DO NOTHING;\"\n",
    "cur.execute(qry)\n",
    "if cur.rowcount > 0:\n",
    "    updated_rows = cur.rowcount\n",
    "else:\n",
    "    print(qry)\n",
    "conn.commit() \n",
    "print(\"%s rows updated\" % (updated_rows))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2f31cc-bf34-4b7b-b108-815fba90b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT * FROM form.surveys;\")\n",
    "surveys = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3344f30-f840-4771-bb9c-6ae7c389d9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TO BE CLASSIFIED',\n",
       "  'Placeholder for field visits not yet assigned to a survey',\n",
       "  'JR Ferrer-Paris'),\n",
       " ('NEWNES', 'NEWNES', None),\n",
       " ('KNP AlpAsh', 'Alpine Ash', None),\n",
       " ('UplandBasalt', 'Upland Basalt', None),\n",
       " ('Alpine Bogs', None, None),\n",
       " ('Robertson RF', None, None),\n",
       " ('Yatteyattah', None, None),\n",
       " ('SthnNSWRF', None, None),\n",
       " ('Rainforests NSW-Qld', 'Rainforests NE NSW & SE Qld', None),\n",
       " ('Mallee Woodlands', None, None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ba5e1-8d6c-4760-9877-88267d4e8fca",
   "metadata": {},
   "source": [
    "### Valid vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25079d27-9d60-4935-82d3-a14b3b3dd484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='resprout_organ_vocabulary';\")\n",
    "valid_organ_list = cur.fetchall()\n",
    "organ_vocab = [item for t in valid_organ_list for item in t]\n",
    "\n",
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='seedbank_vocabulary';\")\n",
    "valid_seedbank_list = cur.fetchall()\n",
    "seedbank_vocab = [item for t in valid_seedbank_list for item in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556673f3-c13d-4cda-9b8c-d846342d5057",
   "metadata": {},
   "source": [
    "### Close DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0dc80c9-9874-4b6f-912f-4b168ddb7847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "cur.close()\n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e52d6-fb39-4c24-8313-876c91cfbfd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import data from each worksheet\n",
    "\n",
    "In the following section, I proceed to iterate through worksheets in the the workbook, using functions defined in the `fireveg` and `firevegdb` modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4a8587-39a6-4b35-ace3-2d3fd12b6c77",
   "metadata": {},
   "source": [
    "Here is the list of available worksheets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06059945-d0ff-48d9-a1db-9879fc6f8b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SiteData', 'FireEvents', 'PlantCounts'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename=valid_files[0]\n",
    "\n",
    "wbindex[filename].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c820990-1773-499e-98d7-c841259d5dfd",
   "metadata": {},
   "source": [
    "### Import site visits records into database\n",
    "\n",
    "- 56 sites/visits in the period 2011 to 2018\n",
    "- But we need to fix the site label to exclude the replicate number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59ba7a9-37a2-421b-af9f-6e71cc3aec11",
   "metadata": {},
   "source": [
    "The original list was incomplete, so we need to read two workbooks. We can retrieve the list of column names that we will use in our column definitions for each function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5650fbaf-cdf8-4f8d-b602-9c6b9e5456ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Site_subplot_census\n",
      "1 :: Site\n",
      "2 :: Subplot\n",
      "3 :: Replicate\n",
      "4 :: Observers (comma sep if >1)\n",
      "5 :: Date of samping\n",
      "6 :: Survey Date Replicate 1\n",
      "7 :: Survey Date Replicate 2\n",
      "8 :: Survey Date Replicate 3\n",
      "9 :: Survey Date Replicate 4\n",
      "10 :: Survey Date Replicate 5\n",
      "11 :: Survey Date Replicate 6\n",
      "12 :: Location text\n",
      "13 :: Zone\n",
      "14 :: Easting\n",
      "15 :: Northing\n",
      "16 :: GPS Precision (m)\n",
      "17 :: Latitude\n",
      "18 :: Longitude\n",
      "19 :: Layout & GPS marker position\n",
      "20 :: 2nd ref point Zone\n",
      "21 :: 2nd ref point Easting\n",
      "22 :: 2nd ref point Northing\n",
      "23 :: 2nd ref point Position of GPS\n",
      "24 :: 3rd ref point Zone\n",
      "25 :: 3rd ref point Easting\n",
      "26 :: 3rd ref point Northing\n",
      "27 :: 3rd ref point Position of GPS\n",
      "28 :: 4th ref point Zone\n",
      "29 :: 4th ref point Easting\n",
      "30 :: 4th ref point Northing\n",
      "31 :: 4th ref point Position of GPS\n",
      "32 :: Total sample area (sq.m)\n",
      "33 :: Subquadrat area (sq.m)\n",
      "34 :: # subquadrats\n",
      "35 :: Substrate\n",
      "36 :: Notes\n",
      "37 :: Slope\n",
      "38 :: Aspect\n",
      "39 :: Elevation\n",
      "40 :: Disturbance notes\n",
      "41 :: Cwth TEC\n",
      "42 :: NSW TEC\n",
      "43 :: variant\n",
      "44 :: Vegetation formation\n",
      "45 :: Vegegtation class\n"
     ]
    }
   ],
   "source": [
    "cols=wbindex[valid_files[0]]['SiteData']\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff732908-8fb6-4e22-a9c9-ca36cae47fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Site_subplot_census\n",
      "1 :: Site\n",
      "2 :: Subplot\n",
      "3 :: Replicate\n",
      "4 :: Observers (comma sep if >1)\n",
      "5 :: Date of samping\n",
      "6 :: Survey Date Replicate 1\n",
      "7 :: Survey Date Replicate 2\n",
      "8 :: Survey Date Replicate 3\n",
      "9 :: Survey Date Replicate 4\n",
      "10 :: Survey Date Replicate 5\n",
      "11 :: Survey Date Replicate 6\n",
      "12 :: Location text\n",
      "13 :: Zone\n",
      "14 :: Easting\n",
      "15 :: Northing\n",
      "16 :: GPS Precision (m)\n",
      "17 :: Latitude\n",
      "18 :: Longitude\n",
      "19 :: Layout & GPS marker position\n",
      "20 :: 2nd ref point Zone\n",
      "21 :: 2nd ref point Easting\n",
      "22 :: 2nd ref point Northing\n",
      "23 :: 2nd ref point Position of GPS\n",
      "24 :: 3rd ref point Zone\n",
      "25 :: 3rd ref point Easting\n",
      "26 :: 3rd ref point Northing\n",
      "27 :: 3rd ref point Position of GPS\n",
      "28 :: 4th ref point Zone\n",
      "29 :: 4th ref point Easting\n",
      "30 :: 4th ref point Northing\n",
      "31 :: 4th ref point Position of GPS\n",
      "32 :: Total sample area (sq.m)\n",
      "33 :: Subquadrat area (sq.m)\n",
      "34 :: # subquadrats\n",
      "35 :: Substrate\n",
      "36 :: Notes\n",
      "37 :: Slope\n",
      "38 :: Aspect\n",
      "39 :: Elevation\n",
      "40 :: Disturbance notes\n",
      "41 :: Cwth TEC\n",
      "42 :: NSW TEC\n",
      "43 :: variant\n",
      "44 :: Vegetation formation\n",
      "45 :: Vegegtation class\n"
     ]
    }
   ],
   "source": [
    "cols=wbindex[valid_files[1]]['Sheet1']\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cdbbd-7f7d-4014-b1ae-93f251498830",
   "metadata": {},
   "source": [
    "Slightly different dictionary for both workbooks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abf3fdb8-4ae7-4390-8e12-fdade4fecf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = {'site_label':1,'location_description':12, 'utm_zone':13,'xs':(14,), 'ys':(15,), \n",
    "        'gps_geom_description':19, \n",
    "         'visit_date':(5,), 'replicate_nr':3,'observerlist':4, 'survey':\"Mallee Woodlands\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee06133d-d5cb-423d-92cf-ac0355b2dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "site_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                               workbook='PlantFireTraitData_2011-2018_Import.xlsx',\n",
    "                                                worksheet='SiteData',\n",
    "                                                col_dictionary=cdict,\n",
    "                                                create_record_function=fv.create_field_site_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0f1ec99-a35d-46ef-8f8f-bbc6ded536f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict2 = {'site_label':0,'location_description':12, 'utm_zone':13,'xs':(14,), 'ys':(15,), \n",
    "        'gps_geom_description':19, \n",
    "         'visit_date':(5,), 'replicate_nr':3,'observerlist':4, 'survey':\"Mallee Woodlands\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46c1ae6b-cd45-4ff0-9ee4-df154781ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_site_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                               workbook=valid_files[1],\n",
    "                                                worksheet='Sheet1',\n",
    "                                                col_dictionary=cdict2,\n",
    "                                                create_record_function=fv.create_field_site_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eec094b2-e2e3-4715-af5e-12fba2e52969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_label': 'S2007/2',\n",
       " 'location_description': 'Scotia Sanctuary, southwestern sector, West of Elliots Bore, edge of burnt area',\n",
       " 'gps_geom_description': 'Centre point at intersection of A, K, R & N subplots with G subplot adjacent and X1-X3 separated and wrapped around G subplot',\n",
       " 'geom': \"ST_GeomFromText('POINT(505169 6318145)', 28354)\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fc7d61c-96fd-4d29-9c87-995467d8b036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(more_site_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "204f1388-08a5-43ba-ae38-65358e657a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "56 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_site\",site_records,keycol=('site_label',), idx='field_site_pkey1',execute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6891b18b-9f01-4fb7-aef9-8287e9b5eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "15 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_site\",more_site_records,keycol=('site_label',), idx='field_site_pkey1',execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d114377-13c0-4333-982c-9e6829b7447c",
   "metadata": {},
   "source": [
    "insert location and visit records based on the sample id, but then, how do we transform the subploots into sample nrs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b69cf3f-f0ed-434d-946d-05c7e6488cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                          workbook='PlantFireTraitData_2011-2018_Import.xlsx',\n",
    "                                            worksheet='SiteData',\n",
    "                                            col_dictionary=cdict,\n",
    "                                            create_record_function=fv.create_field_visit_record) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a8929717-71be-4c63-8947-69696bc5d74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/2',\n",
       " 'visit_date': datetime.datetime(2013, 9, 24, 0, 0),\n",
       " 'survey_name': 'Mallee Woodlands',\n",
       " 'observerlist': ['David Keith'],\n",
       " 'replicate_nr': 3}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8f03cf4-0330-4a67-b183-1b6185483176",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_visit_records = fv.import_records_from_workbook(filepath=inputdir,\n",
    "                                          workbook=valid_files[1],\n",
    "                                            worksheet='Sheet1',\n",
    "                                            col_dictionary=cdict2,\n",
    "                                            create_record_function=fv.create_field_visit_record) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25a841d6-fd2d-4050-96b2-36baf8af4481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2010/2',\n",
       " 'visit_date': datetime.datetime(2011, 10, 7, 0, 0),\n",
       " 'survey_name': 'Mallee Woodlands',\n",
       " 'replicate_nr': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_visit_records[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f227615-f291-4060-aff0-10fc89ea4989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "53 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_visit\",visit_records,keycol=('visit_id','visit_date'), idx='field_visit_pkey2',execute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ba19ee4a-ac6c-4db0-b37d-1ca3a05b1cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "42 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_visit\",more_visit_records,keycol=('visit_id','visit_date'), idx='field_visit_pkey2',execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b360c-794e-42f7-ac0c-11902d42132f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Import fire history records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5a9f2-fe0a-4a32-a2b7-e3129ecc44bc",
   "metadata": {},
   "source": [
    "This was provided by David in May 2023, check if it works..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b93a5afc-c4cb-47cd-bf9e-e25a55dbd9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Site\n",
      "1 :: Replicate\n",
      "2 :: Date of last fire dd/mm/yyyy\n",
      "3 :: Date of penultimate fire\n",
      "4 :: Date of earlier fire\n",
      "5 :: How date inferred1\n",
      "6 :: How date inferred2\n",
      "7 :: How date inferred3\n",
      "8 :: Ignition cause1\n",
      "9 :: Ignition cause2\n",
      "10 :: Ignition cause3\n",
      "11 :: Scorch hgt (m) min\n",
      "12 :: Scorch hgt (m) mas\n",
      "13 :: Scorch hgt (m) mode\n",
      "14 :: % Tree foliage scorch\n",
      "15 :: % Tree foliage c'sume\n",
      "16 :: % Shb foliage scorch\n",
      "17 :: % Shb foliage c'sume\n",
      "18 :: % Herb layer foliage scorch\n",
      "19 :: % Herb layer foliage c'sume\n",
      "20 :: Twig diam (mm) 1\n",
      "21 :: Twig diam (mm) 2\n",
      "22 :: Twig diam (mm) 3\n",
      "23 :: Twig diam (mm) 4\n",
      "24 :: Twig diam (mm) 5\n",
      "25 :: Twig diam (mm) 6\n",
      "26 :: Twig diam (mm) 7\n",
      "27 :: Twig diam (mm) 8\n",
      "28 :: Twig diam (mm) 9\n",
      "29 :: Twig diam (mm) 10\n",
      "30 :: Peat depth burnt (cm)\n",
      "31 :: Peat extent burnt %quad\n"
     ]
    }
   ],
   "source": [
    "worksheet = 'FireEvents'\n",
    "#wbindex[filename][worksheet][0][0:13]\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5f9f4f3-7a77-4135-8224-6d8aa9865a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "833"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_dicts=[{'site_label':0,'fire_date':2,'how_inferred':5,'cause_of_ignition':8},\n",
    "    {'site_label':0,'fire_date':3,'how_inferred':6,'cause_of_ignition':9},\n",
    "    {'site_label':0,'fire_date':4,'how_inferred':7,'cause_of_ignition':10}]\n",
    "fire_records = fv.import_records_from_workbook(inputdir, filename, worksheet, col_dicts, create_record_function=fv.create_fire_history_record)\n",
    "len(fire_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bce37286-130b-4e69-986c-301692f70b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_label': 'S2007/1_X1_3',\n",
       " 'fire_date': '2006-11-01',\n",
       " 'earliest_date': datetime.date(2006, 11, 1),\n",
       " 'latest_date': datetime.date(2006, 11, 1),\n",
       " 'how_inferred': 'Land manager records & pers obs'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_records[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c438a0-1853-471e-a364-542f6c0185c1",
   "metadata": {},
   "source": [
    "Need to adjust the site label (remove the trailing replicate number, and include all the missing site labels (sites with fire history but no visit recorded yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1e35c82-3686-4aa2-b88f-2ef829661ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sites = list()\n",
    "for record in fire_records:\n",
    "    record['site_label']=re.sub(\"_[AKRNGX123]+_[0-9]$\", \"\", record['site_label'])\n",
    "    all_sites.append(record['site_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7ca9a17-3e1e-4133-8298-e02bd4322670",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_site_records=list()\n",
    "all_sites = set(all_sites)\n",
    "\n",
    "for site in all_sites:\n",
    "    add_site_records.append({'site_label':site})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c79c7bc-f164-41be-8985-3d75ea589d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(add_site_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ae7017a-5e91-4a66-a554-61dab02dbe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'site_label': 'S2011/1'},\n",
       " {'site_label': 'T1996/1'},\n",
       " {'site_label': 'S2012/6'},\n",
       " {'site_label': 'T1997/2'},\n",
       " {'site_label': 'T2003/2'},\n",
       " {'site_label': 'S2007/7'},\n",
       " {'site_label': 'T2006/3'},\n",
       " {'site_label': 'T2011/2'},\n",
       " {'site_label': 'T2017/4'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_site_records[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71e6930d-e858-401b-b209-8944f423b201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.field_site\",add_site_records,keycol=(), idx=None,execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa9fd93-d1b4-41a5-9d4d-f116910cab8f",
   "metadata": {},
   "source": [
    "Now we can do the batch upsert of all the fire history records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12924461-2533-4635-a8ae-7b44be2ce521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "639 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "batch_upsert(dbparams,\"form.fire_history\",fire_records,keycol=('site_label','fire_date'), idx='fire_history_pkey1',execute=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5480595-a356-4738-81d7-c3b7298879ac",
   "metadata": {},
   "source": [
    "### Import plant count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a72ccac-4c15-4d56-a802-223555623ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: site_subplot_cen\n",
      "1 :: Species_name\n",
      "2 :: Recovery organ\n",
      "3 :: Seedbank\n",
      "4 :: Count of unburnt adlt individuals\n",
      "5 :: Count of unburnt juv individuals\n",
      "6 :: Count of resprouting juv individuals.\n",
      "7 :: Count of resprouting adult individuals.\n",
      "8 ::  # resprouted & died post-fire\n",
      "9 :: Count of fire-killed juv individuals\n",
      "10 :: Count of fire-killed adult individuals\n",
      "11 :: #  reproductive pre-fire plants\n",
      "12 :: Count of live postfire recruits\n",
      "13 :: #  reproductive post-fire recruits\n",
      "14 :: # recruits died post-fire\n",
      "15 :: # reproductive recruits died post-fire\n",
      "16 :: # live interfire recruits (>3yr postfire emerg\n",
      "17 :: # live reproductive interfire recruits (>3yr postfire emerg\n",
      "18 :: # deadinterfire recruits (>3yr postfire emerg)\n"
     ]
    }
   ],
   "source": [
    "worksheet = 'PlantCounts'\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols)):\n",
    "    print(\"%s :: %s\" % (k-1,cols[k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9baef3-11c6-49e2-8f39-e98d80da248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict={'visit_id':0, 'species':1,   \n",
    "          'resprout_organ':2, 'seedbank':3,\n",
    "          'adults_unburnt':4,\n",
    "          'resprouts_live':6,\n",
    "          'resprouts_kill':8,\n",
    "          'resprouts_reproductive':7,\n",
    "          'recruits_live':12, \n",
    "          'recruits_died':14, \n",
    "          'recruits_reproductive':13,\n",
    "          'split_visit_id': True,\n",
    "          'notes':19,'workbook':filename,'worksheet':worksheet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e82484ca-956a-4e96-bc8d-8bdab816858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quadrats = fv.import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                       fv.create_field_sample_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37543ed2-1920-4b43-b03d-6bb476881322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9051"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quadrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db95b956-047b-43b5-92f4-7cfa881d55a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/1', 'replicate_nr': 3, 'sample_nr': 'X2'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadrats[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c14845d-23d3-4782-9c86-695123c273cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = {\"A\":1,\"K\":2,\"R\":3,\"N\":4,\"G\":5,\"X1\":6,\"X2\":7,\"X3\":8,\n",
    "           \"AX\":9, \"KX\":10, \"RX\":11, \"NX\":12,}\n",
    "for record in quadrats:\n",
    "    if record['sample_nr']:\n",
    "        record['sample_nr']=samples[record['sample_nr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87ac96c1-7120-4d23-a9bf-da4141dbcda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/1', 'replicate_nr': 3, 'sample_nr': 7}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadrats[175]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53272920-27b1-4099-8157-7706f5414791",
   "metadata": {},
   "source": [
    "Now check which ones are valid visit records (already present in the database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3404e0e-65a4-4c13-8de9-03d50fbda901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K250 not found\n",
      "K251 not found\n",
      "K253 not found\n",
      "K254 not found\n",
      "K258 not found\n",
      "K259 not found\n",
      "K260 not found\n",
      "K261 not found\n",
      "K265 not found\n",
      "K266 not found\n",
      "K267 not found\n",
      "K268 not found\n",
      "record for S2010/1 is incomplete\n",
      "record for S2010/1 is incomplete\n",
      "record for S2010/1 is incomplete\n",
      "record for S2010/1 is incomplete\n",
      "record for S2010/1 is incomplete\n",
      "record for S2010/2 is incomplete\n",
      "record for S2010/2 is incomplete\n",
      "record for S2010/2 is incomplete\n",
      "record for S2010/2 is incomplete\n",
      "record for S2010/2 is incomplete\n",
      "record for S2010/3 is incomplete\n",
      "record for S2010/3 is incomplete\n",
      "record for S2010/3 is incomplete\n",
      "record for S2010/3 is incomplete\n",
      "record for S2010/3 is incomplete\n",
      "record for S2010/4 is incomplete\n",
      "record for S2010/4 is incomplete\n",
      "record for S2010/4 is incomplete\n",
      "record for S2010/4 is incomplete\n",
      "record for S2010/4 is incomplete\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "S2011/1 not found\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/1 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/2 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/4 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/6 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "record for S2012/7 is incomplete\n",
      "T1998/CON1 not found\n",
      "T1998/CON1 not found\n",
      "T1998/CON1 not found\n",
      "T1998/CON1 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "T2003/3 not found\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/1 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/2 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/3 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/4 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2005/5 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/1 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/2 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/3 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2006/4 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/1 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "record for T2011/4 is incomplete\n",
      "327 rows updated\n"
     ]
    }
   ],
   "source": [
    "new_conn = psycopg2.connect(**dbparams)\n",
    "valid_visits = validate_and_update_site_records(quadrats,useconn=new_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "681922ef-e2e4-4c5e-b206-a767c32fdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a21b6e5a-77ed-47b3-858e-04b45e97df27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_visits)\n",
    "#len(quadrats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56ed6149-c73c-4a12-80a4-5be9f0cfae2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2007/6', datetime.date(2013, 4, 11), 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_visits[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "409d0493-cca5-4f2b-89b3-481b1cd2028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "records=fv.import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                         fv.create_quadrat_sample_record,\n",
    "                                         lookup=valid_visits, \n",
    "                                        valid_seedbank=seedbank_vocab, \n",
    "                                        valid_organ=organ_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eef0921a-c681-47c4-9543-59f9381a060b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'S2007/6',\n",
       " 'sample_nr': 'X1',\n",
       " 'species': 'Triodia scariosa',\n",
       " 'visit_date': datetime.date(2013, 4, 11),\n",
       " 'resprouts_live': 0,\n",
       " 'resprouts_kill': 0,\n",
       " 'resprouts_reproductive': 34,\n",
       " 'comments': ['visit_id originally recorded as S2007/6_X1_3',\n",
       "  'Imported from workbook PlantFireTraitData_2011-2018_Import.xlsx using python script',\n",
       "  'Imported from spreadsheet PlantCounts',\n",
       "  'matched by replicate nr 3, assuming date object',\n",
       "  'resprout organ written as rhizome short',\n",
       "  'seedbank written as soil persistent']}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[555]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66640f4b-804e-4729-91bb-cf464bfc2716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5152 valid records and 3905 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "5152 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "samples = {\"A\":1,\"K\":2,\"R\":3,\"N\":4,\"G\":5,\"X1\":6,\"X2\":7,\"X3\":8,\n",
    "           \"AX\":9, \"KX\":10, \"RX\":11, \"NX\":12,}\n",
    "valid_records=list()\n",
    "invalid_records=list()\n",
    "for record in records:\n",
    "    if 'visit_date' in record.keys():\n",
    "        if record['sample_nr']:\n",
    "            record['sample_nr']=samples[record['sample_nr']]\n",
    "        valid_records.append(record)\n",
    "    else:\n",
    "        invalid_records.append(record)\n",
    "\n",
    "print(\"%s valid records and %s invalid records\" % (len(valid_records), len(invalid_records)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6edf5d1b-d7e6-4999-a575-918d1c25d3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "5152 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_upsert(dbparams,table='form.quadrat_samples',\n",
    "             records=valid_records,\n",
    "             keycol=('visit_id','visit_date','sample_nr'),\n",
    "             idx=None, execute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b39deb3f-7cd6-40c6-99b5-b180b4892154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'visit_id': 'T2017/5',\n",
       " 'sample_nr': 11,\n",
       " 'species': 'Triodia scariosa',\n",
       " 'visit_date': datetime.date(2017, 3, 25),\n",
       " 'adults_unburnt': 57,\n",
       " 'comments': ['visit_id originally recorded as T2017/5_RX_1',\n",
       "  'Imported from workbook PlantFireTraitData_2011-2018_Import.xlsx using python script',\n",
       "  'Imported from spreadsheet PlantCounts',\n",
       "  'matched by replicate nr 1, assuming date object',\n",
       "  'resprout organ written as rhizome short',\n",
       "  'seedbank written as soil persistent']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61243b2-3078-4947-9e48-b744480a7118",
   "metadata": {},
   "source": [
    "Done, next steps:\n",
    "- fill the species code column for all these species. Check the other notebooks for updating species list.\n",
    "- Check the invalid records (site labels not in the database, why?)\n",
    "- Once the missing site labels have been sorted we need to run again, any duplicates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9bcefe4e-9371-4f7a-820d-64c6151193a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tabulate import tabulate\n",
    "#from IPython.display import HTML, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d006a14-7f19-4701-a957-2143c354abb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>S2010/1   </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>          </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>S2010/2   </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>S2011/1   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>T2005/1   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>K254      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2006/1   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>K253      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T1998/CON1</td><td style=\"text-align: right;\"> </td></tr>\n",
       "<tr><td>T2006/4   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>K268      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>S2012/4   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>S2012/6   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>K267      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2006/2   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>K266      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2011/1   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>S2012/7   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>S2011/1   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>T2005/2   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2003/3   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2011/4   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2006/4   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "<tr><td>K259      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>K250      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>K265      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2005/5   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2017/2   </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>K251      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2006/3   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2006/1   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>K260      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>S2010/4   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>K258      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>S2010/3   </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>S2012/1   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>S2012/2   </td><td style=\"text-align: right;\">2</td></tr>\n",
       "<tr><td>K261      </td><td style=\"text-align: right;\">6</td></tr>\n",
       "<tr><td>T2005/3   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2005/4   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2006/2   </td><td style=\"text-align: right;\">4</td></tr>\n",
       "<tr><td>T2017/3   </td><td style=\"text-align: right;\">1</td></tr>\n",
       "<tr><td>T2006/3   </td><td style=\"text-align: right;\">3</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vids=list()\n",
    "for record in invalid_records:\n",
    "    vids.append((record['visit_id'],record['replicate_nr']))\n",
    "\n",
    "#table = tabulate(set(vids), tablefmt='html')\n",
    "\n",
    "#display(HTML(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "14eebf6a-33f9-4a11-861d-d33d4e1551d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(vids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0404c-1456-42e5-bb07-ae40a344ddad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
