{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815a2392-ade6-4043-a754-c5fc8b43b017",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read files summarising field work and update database\n",
    "These Excel workbooks were imported on February 2022.\n",
    "\n",
    "The scripts documented here have been created to:\n",
    "\n",
    "- Read data from spreadsheets with field-work data\n",
    "- Create records for data import into the database\n",
    "- Insert or update records in the database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de45e0-a286-4a28-90b7-32af9bd311e0",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "Load libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47eadb90-b36c-4ae6-a783-7b8e9c4f6218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime\n",
    "from configparser import ConfigParser\n",
    "import psycopg2\n",
    "from psycopg2.extras import DictCursor\n",
    "from psycopg2.extensions import AsIs\n",
    "import pyprojroot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a20b05-6d18-4338-ae2c-55dd23cef032",
   "metadata": {},
   "source": [
    "Load functions from `lib` folder, we will use a function to read db credentials and one for batch insert and updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74817a2e-b1bd-499b-9ffe-690b9e5a7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.parseparams import read_dbparams\n",
    "from lib.firevegdb import batch_upsert\n",
    "import lib.fireveg as fv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf9fde4-3058-4347-8847-f7486326d23e",
   "metadata": {},
   "source": [
    "Define path to workbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685f98ff-9f63-413d-b6be-d77398ca4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repodir = pyprojroot.find_root(pyprojroot.has_dir(\".git\"))\n",
    "inputdir = repodir / \"data\" / \"input-field-form\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31a1bca-5138-4647-ac4f-c9a310478212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbparams = read_dbparams(repodir / 'secrets' / 'database.ini', section='aws-lght-sl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ca7d6-91a0-4c1c-827e-f46d39a346f0",
   "metadata": {},
   "source": [
    "Get updated vocabularies from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454b734d-a061-4ebe-9b2b-e0d03693b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# connect to the PostgreSQL server\n",
    "print('Connecting to the PostgreSQL database...')\n",
    "conn = psycopg2.connect(**dbparams)\n",
    "cur = conn.cursor()\n",
    "#valid_organ=('Epicormic', 'Apical', 'Lignotuber', 'Basal','Tuber','Tussock','Short rhizome', 'Long rhizome or root sucker', 'Stolon', 'None', 'Other')\n",
    "#valid_seedbank=('Soil-persistent', 'Transient', 'Canopy','Non-canopy','Other')\n",
    "\n",
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='resprout_organ_vocabulary';\")\n",
    "valid_organ_list = cur.fetchall()\n",
    "organ_vocab = [item for t in valid_organ_list for item in t]\n",
    "\n",
    "cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='seedbank_vocabulary';\")\n",
    "valid_seedbank_list = cur.fetchall()\n",
    "seedbank_vocab = [item for t in valid_seedbank_list for item in t]\n",
    "\n",
    "cur.close()\n",
    "        \n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddb5c73-aafa-4c0c-95b3-08718b4649cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Epicormic',\n",
       " 'Apical',\n",
       " 'Lignotuber',\n",
       " 'Basal',\n",
       " 'Tuber',\n",
       " 'Tussock',\n",
       " 'Short rhizome',\n",
       " 'Long rhizome or root sucker',\n",
       " 'Stolon',\n",
       " 'None',\n",
       " 'Other']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organ_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ffc73-f2c2-4ce1-b137-ff58a54d44a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read workbooks\n",
    "Each spreadsheet has a slightly different structure, so these scripts have to be adapted for each case.\n",
    "\n",
    "### List of workbooks/spreadsheets in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef766fae-b8d3-440a-abc5-c4db547f7b7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PlantFireTraitData_2011-2018_Import.xlsx',\n",
       " 'SthnNSWRF_data_bionet2.xlsx',\n",
       " 'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton.xlsx',\n",
       " 'UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx',\n",
       " 'RobertsonRF_data_bionet2.xlsx',\n",
       " 'UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx',\n",
       " 'UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx',\n",
       " 'UNSW_VegFireResponse_KNP AlpAsh.xlsx',\n",
       " 'Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm',\n",
       " 'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(inputdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e4f052a-4351-40bc-ab3c-920431d42c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_files = ['SthnNSWRF_data_bionet2.xlsx',\n",
    "               'UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx',\n",
    "               'UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx',\n",
    "               'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx',\n",
    "               'UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx',\n",
    "               'UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx',\n",
    "               'RobertsonRF_data_bionet2.xlsx',\n",
    "               'Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa2020-e8d8-4817-9498-f0155118ca1c",
   "metadata": {},
   "source": [
    "Here we create an index of worksheets and column headers for each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aba9482-c09f-4aff-be77-6cfd9ff08cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wbindex=dict()\n",
    "for workbook_name in valid_files:\n",
    "    inputfile=inputdir / workbook_name\n",
    "    # using data_only=True to get the calculated cell values\n",
    "    wb = openpyxl.load_workbook(inputfile,data_only=True)\n",
    "    wbindex[workbook_name]=dict()\n",
    "    for ws in wb.worksheets:\n",
    "        wbindex[workbook_name][ws._WorkbookChild__title]=[list(),list()]\n",
    "        for k in range(1,ws.max_column):\n",
    "            wbindex[workbook_name][ws._WorkbookChild__title][0].append(ws.cell(row=1,column=k).value)\n",
    "            wbindex[workbook_name][ws._WorkbookChild__title][1].append(ws.cell(row=2,column=k).value)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d91de-71ab-4b27-a306-58494eb26dd4",
   "metadata": {},
   "source": [
    "### Functions to read records and upload to database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f8bf5d-9afd-4cf9-a366-1fd3bcf3fb8f",
   "metadata": {},
   "source": [
    "To use this function we need to select an item (row) from the target workbook/worksheet for example:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2319a7f-cc1a-44ab-a39d-0a574da9fb34",
   "metadata": {},
   "source": [
    "filename=valid_files[4]\n",
    "worksheet='Floristics'\n",
    "wb = openpyxl.load_workbook(inputdir / filename, data_only=True)\n",
    "ws = wb[worksheet]\n",
    "k = 965\n",
    "item = ws[k]\n",
    "\n",
    "col_dict={'visit_id':0, 'sample_nr':1, 'fixed_replicate_nr':1,'species':6, 'spcode':4,  'resprout_organ':8, 'seedbank':9,\n",
    "          'adults_unburnt':10,'resprouts_live':11,'resprouts_died':12,'resprouts_kill':13,\n",
    "          'resprouts_reproductive':14,'recruits_live':15, 'recruits_died':16, 'recruits_reproductive':17,\n",
    "                 'notes':18,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "fv.create_quadrat_sample_record(item,col_dict,valid_visits,seedbank_vocab,organ_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc3543e-91fd-4f9b-a305-37d0bd33f090",
   "metadata": {},
   "source": [
    "#### Wrapping all steps together\n",
    "The following function will the above functions `import_records_from_workbook`, `create_field_sample_record`, `validate_and_update_site_records`, and `create_quadrat_sample_record` to process data from a workbook into records that are then imported into the database using `batch_upsert`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36559fb6-757f-4755-9424-657a9ba5f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_import_species_data(filepath,workbook,worksheet,col_dictionary,valid_seedbank,valid_organ):\n",
    "    quadrats = fv.import_records_from_workbook(filepath, workbook, worksheet, col_dictionary,\n",
    "                                       create_field_sample_record)\n",
    "    valid_visits = fv.validate_and_update_site_records(quadrats)\n",
    "    \n",
    "    records=fv.import_records_from_workbook(filepath, workbook, worksheet, col_dictionary,\n",
    "                                         fv.create_quadrat_sample_record,\n",
    "                                         lookup=valid_visits, valid_seedbank=valid_seedbank, valid_organ=valid_organ)\n",
    "    valid_records=list()\n",
    "    invalid_records=list()\n",
    "    for record in records:\n",
    "        if 'replicate_nr' in record.keys():\n",
    "            replicate_nr = record['replicate_nr']\n",
    "        elif 'fixed_replicate_nr' in record.keys():\n",
    "            replicate_nr = col_dictionary['fixed_replicate_nr']\n",
    "        else:\n",
    "            replicate_nr = None\n",
    "        \n",
    "        if 'visit_date' in record.keys():\n",
    "            p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['visit_date'] == record['visit_date'], valid_visits)\n",
    "            found=list(p)\n",
    "        elif 'replicate_nr' in record.keys():\n",
    "            p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['replicate_nr'] == replicate_nr, valid_visits)\n",
    "            found=list(p)\n",
    "        else:\n",
    "            found=list()\n",
    "        \n",
    "        if (len(found)==1):\n",
    "            valid_records.append(record)\n",
    "        else:\n",
    "            invalid_records.append(record)\n",
    "\n",
    "    print(\"%s valid records and %s invalid records\" % (len(valid_records), len(invalid_records)))\n",
    "    \n",
    "    batch_upsert(params,table='form.quadrat_samples',records=valid_records,keycol=('visit_id','visit_date','sample_nr'),\n",
    "             idx=None, execute=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb620012-e7c6-4ba6-9ec9-ca0d72cd8b3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Processing data from all workbooks\n",
    "\n",
    "In the following section, I proceed to iterate through all the workbooks, adjusting code for each case. \n",
    "\n",
    "Here is the list of available workbooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0efd041-2cf8-4e73-aa31-c29962629fef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SthnNSWRF_data_bionet2.xlsx', 'UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx', 'UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx', 'UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx', 'UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx', 'UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx', 'RobertsonRF_data_bionet2.xlsx', 'Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wbindex.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3e741-28a5-41b5-aff5-b41ec0ece563",
   "metadata": {
    "tags": []
   },
   "source": [
    "If we select one workbook, we can retrieve a list of column names that we will use in our column definitions for each function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f1d3e5-448a-4067-9b22-ec7e7e832225",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Upland / Basalt\n",
    "\n",
    "- 15 visits (older) without data\n",
    "- most visits with 3 quadrats or samples\n",
    "- around 30 to 50 spp per visit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d257301-42a3-4a41-8bec-8e0cf23f513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Updated 14/10/2019 / Entry Order\n",
      "1 :: Site Number / Site Number\n",
      "2 :: Replicate / Replicate\n",
      "3 :: First Date / Date of sighting (dd/mm/yyyy hh:mm:ss).\n",
      "4 :: Last Date / If more than 1 day (dd/mm/yyyy hh:mm:ss).\n",
      "5 :: Sub plot / None\n",
      "6 :: Type / Fauna (FA) or flora (FL).\n",
      "7 :: Species code / Species code can be assigned by OEH, or see the reference worksheet.\n",
      "8 :: Common Name / None\n",
      "9 :: Scientific Name / ScientificName\n",
      "10 :: Cover score / See reference worksheet for definitions\n",
      "11 :: Abundance score / None\n",
      "12 :: Stratum / See reference worksheet for definitions\n",
      "13 :: Growth form / See reference worksheet for definitions\n",
      "14 :: Height min / Flora only; height (in metres)\n",
      "15 :: Height max / Flora only; height (in metres)\n",
      "16 :: % Cover actual / None\n",
      "17 :: Recovery organ / Recovery organ\n",
      "18 :: Seedbank / Seedbank\n",
      "19 :: None / Count of unburnt individuals\n",
      "20 :: Abund actual / Count of resprouting individuals.\n",
      "21 :: None / Count of fire-killed individuals\n",
      "22 :: Number reproductive / None\n",
      "23 :: None / Count of live postfire recruits\n",
      "24 :: None / # recruits died post-fire\n",
      "25 :: None / #  reproductive recruits\n",
      "26 :: Estimate Code / Accuracy of count. See reference worksheet for definitions.\n",
      "27 :: Source Code / Source of the sighting; automatically populated as '4 - sighting'. Alter if specimen lodged or sighting is questionable (e.g. Anabat). See reference worksheet for definitions.\n",
      "28 :: Specimen Rego / Registration number (if the specimen has been lodged with a herbarium or museum).\n",
      "29 :: Specimen Location / Location of the herbarium or museum (if the specimen has been lodged). See reference worksheet for definitions.\n",
      "30 :: External Key / Observers' own unique reference number.\n",
      "31 :: Notes / Any additional notes about the sighting.\n"
     ]
    }
   ],
   "source": [
    "filename='UNSWFireVegResponse_UplandBasalt_AlexThomsen+DK.xlsx'\n",
    "worksheet='Floristics'\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db5ad5d9-7f93-4fd4-8701-976fdfe765a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "SiteNo not found\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "1590 valid records and 2 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "1590 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_dict={'visit_id':1, 'replicate_nr':2, 'date':3,\n",
    "          'sample_nr':5, 'spcode':7, 'species':9,   \n",
    "          'resprout_organ':17, 'seedbank':18,\n",
    "          'adults_unburnt':19,'resprouts_live':20,'resprouts_kill':21,\n",
    "          'resprouts_reproductive':22,'recruits_live':23, 'recruits_died':24, 'recruits_reproductive':25,\n",
    "                 'notes':31,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da26ed-ade9-46a8-aec0-686fb5b6ad3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Rainforest in NE NSW / SE Qld\n",
    "\n",
    "- Original did not  have visit_date or replicate nr.\n",
    "- Edited file to add replicate nr (nr. 2 for BFEH_1_UNSW and BFEH_4_UNSW, nr 1 for all others)\n",
    "\n",
    "Several updates to the script were needed to finally make it work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cf7a76-6fa5-493c-bcf2-591ec49cbd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: None // Site\n",
      "1 :: None // replicate nr\n",
      "2 :: Species responses // Subquadrat #\n",
      "3 :: None // Label\n",
      "4 :: Type // Fauna (FA) or flora (FL).\n",
      "5 :: Species code // Species code can be assigned by OEH, or see the reference worksheet.\n",
      "6 :: Common Name // Common name\n",
      "7 :: None // Species (edits in red)\n",
      "8 :: None // CAPS #\n",
      "9 :: None // resprout organ (epicormic,ligno, crown, basal, tuber,rhiz,stol)\n",
      "10 :: None // seedbank type (canopy, soil, transient, other(not canopy)\n",
      "11 :: None // # Live unburnt (no response to fire)\n",
      "12 :: Adults // # resprouted & live\n",
      "13 :: None //  # resprouted & died post-fire\n",
      "14 :: None // # killed in fire\n",
      "15 :: None // #  reproductive\n",
      "16 :: Recruits // # live\n",
      "17 :: None // # died post-fire\n",
      "18 :: None // #  reproductive\n",
      "19 :: None // notes\n"
     ]
    }
   ],
   "source": [
    "filename='UNSW_VegFireResponse_RMK_reformat_Sep2021a.xlsx'\n",
    "worksheet='Floristics'\n",
    "\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])):\n",
    "    print(\"%s :: %s // %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6853e03d-605f-477a-9081-74407b74ecba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "2480 valid records and 1 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "2480 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# does not have visit_date or replicate nr, assuming 1\n",
    "col_dict={'visit_id':0, 'sample_nr':2, 'replicate_nr':1,'species':7, 'spcode':5,  'resprout_organ':9, 'seedbank':10,\n",
    "          'adults_unburnt':11,'resprouts_live':12,'resprouts_died':13,'resprouts_kill':14,\n",
    "          'resprouts_reproductive':15,'recruits_live':16, 'recruits_died':17, 'recruits_reproductive':18,\n",
    "                 'notes':19,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16fadf2-69f9-4209-9288-25307cc28e86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Southern NSW Rainforest\n",
    "\n",
    "- Edited file, all these UppClydeRF1, UppClydeRF2, UppClydeRF3, UppClydeRF4 corrected to UppClyde1\n",
    "- This validates all 250 records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd15db74-7477-4e3b-9434-4b54ddbe38b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Updated 14/10/2019 // Entry Order\n",
      "1 :: None // Site Number\n",
      "2 :: None // Replicate\n",
      "3 :: First Date // Date of sighting (dd/mm/yyyy hh:mm:ss).\n",
      "4 :: Last Date // If more than 1 day (dd/mm/yyyy hh:mm:ss).\n",
      "5 :: Sub plot // SubplotID\n",
      "6 :: Type // Fauna (FA) or flora (FL).\n",
      "7 :: Species code // Species code can be assigned by OEH, or see the reference worksheet.\n",
      "8 :: Common Name // None\n",
      "9 :: Scientific Name // None\n",
      "10 :: Cover score // See reference worksheet for definitions\n",
      "11 :: Abundance score // CV18A See reference worksheet for definitions\n",
      "12 :: Stratum // See reference worksheet for definitions\n",
      "13 :: Growth form // See reference worksheet for definitions\n",
      "14 :: Height min // Flora only; height (in metres)\n",
      "15 :: Height max // Flora only; height (in metres)\n",
      "16 :: % Cover actual // None\n",
      "17 :: Recovery organ // None\n",
      "18 :: Seedbank // None\n",
      "19 :: None // Count of unburnt individuals\n",
      "20 :: Abund actual // Count of resprouting individuals.\n",
      "21 :: None //  # resprouted & died post-fire\n",
      "22 :: None // Count of fire-killed individuals\n",
      "23 :: Number reproductive // #  reproductive pre-fire plants\n",
      "24 :: None // Count of live postfire recruits\n",
      "25 :: None // # recruits died post-fire\n",
      "26 :: Number reproductive // #  reproductive recruits\n",
      "27 :: Estimate Code // Accuracy of count. See reference worksheet for definitions.\n",
      "28 :: Source Code // Source of the sighting; automatically populated as '4 - sighting'. Alter if specimen lodged or sighting is questionable (e.g. Anabat). See reference worksheet for definitions.\n",
      "29 :: Specimen Rego // Registration number (if the specimen has been lodged with a herbarium or museum).\n",
      "30 :: Specimen Location // Location of the herbarium or museum (if the specimen has been lodged). See reference worksheet for definitions.\n",
      "31 :: External Key // Observers' own unique reference number.\n"
     ]
    }
   ],
   "source": [
    "cols=wbindex['SthnNSWRF_data_bionet2.xlsx']['Floristics']\n",
    "for k in range(1,len(cols[0])):\n",
    "    print(\"%s :: %s // %s\" % (k-1,cols[0][k-1],cols[1][k-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70e582f4-bd38-4e56-8238-ab7327298f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "250 valid records and 0 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "250 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "filename='SthnNSWRF_data_bionet2.xlsx'\n",
    "worksheet='Floristics'\n",
    "col_dict={'visit_id':1, 'sample_nr':5, 'replicate_nr':2,'species':9, 'spcode':7, 'date':3, 'resprout_organ':17, 'seedbank':18,\n",
    "          'adults_unburnt':19,'resprouts_live':20,'resprouts_died':21,'resprouts_kill':22,\n",
    "          'resprouts_reproductive':23,'recruits_live':24, 'recruits_died':25, 'recruits_reproductive':26,\n",
    "                 'notes':32,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba898c5-33ae-4511-82be-b4b6c690c8f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### KNP Alpine Ash\n",
    "\n",
    "AlpAsh26 is not in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bed901c-0741-41ce-b1bd-57f8435e66a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Updated 14/10/2019 / Entry Order\n",
      "1 :: None / Site Number\n",
      "2 :: None / Replicate\n",
      "3 :: First Date / Date of sighting (dd/mm/yyyy hh:mm:ss).\n",
      "4 :: Last Date / If more than 1 day (dd/mm/yyyy hh:mm:ss).\n",
      "5 :: Sub plot / SubplotID\n",
      "6 :: Type / Fauna (FA) or flora (FL).\n",
      "7 :: Species code / Species code can be assigned by OEH, or see the reference worksheet.\n",
      "8 :: Common Name / None\n",
      "9 :: Scientific Name / Scientific Name\n",
      "10 :: Cover score / See reference worksheet for definitions\n",
      "11 :: Abundance score / CV18A See reference worksheet for definitions\n",
      "12 :: Stratum / See reference worksheet for definitions\n",
      "13 :: Growth form / See reference worksheet for definitions\n",
      "14 :: Height min / Flora only; height (in metres)\n",
      "15 :: Height max / Flora only; height (in metres)\n",
      "16 :: % Cover actual / None\n",
      "17 :: Recovery organ / None\n",
      "18 :: Seedbank / None\n",
      "19 :: 0 / Count of unburnt individuals\n",
      "20 :: Abund actual / Count of resprouting individuals.\n",
      "21 :: 0 /  # resprouted & died post-fire\n",
      "22 :: None / Count of fire-killed individuals\n",
      "23 :: Number reproductive / #  reproductive pre-fire plants\n",
      "24 :: None / Count of live postfire recruits\n",
      "25 :: None / # recruits died post-fire\n",
      "26 :: Number reproductive / #  reproductive recruits\n",
      "27 :: Estimate Code / Accuracy of count. See reference worksheet for definitions.\n",
      "28 :: Source Code / Source of the sighting; automatically populated as '4 - sighting'. Alter if specimen lodged or sighting is questionable (e.g. Anabat). See reference worksheet for definitions.\n",
      "29 :: Specimen Rego / Registration number (if the specimen has been lodged with a herbarium or museum).\n",
      "30 :: Specimen Location / Location of the herbarium or museum (if the specimen has been lodged). See reference worksheet for definitions.\n",
      "31 :: External Key / Observers' own unique reference number.\n",
      "32 :: Notes / Any additional notes about the sighting.\n"
     ]
    }
   ],
   "source": [
    "worksheet='Floristics'\n",
    "filename='UNSW_VegFireResponse_KNP AlpAsh_firehistupdate.xlsx'\n",
    "\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dd56e82-24fd-4f76-80bc-593e1f507ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "769 valid records and 1 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "769 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "col_dict={'visit_id':1, 'replicate_nr':2, 'date':3,\n",
    "          'sample_nr':5, 'spcode':7, 'species':9,   \n",
    "          'resprout_organ':17, 'seedbank':18,\n",
    "          'adults_unburnt':19,'resprouts_live':20,'resprouts_died':21,'resprouts_kill':22,\n",
    "          'resprouts_reproductive':23,'recruits_live':24, 'recruits_died':25, 'recruits_reproductive':26,\n",
    "                 'notes':32,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db592a-f4a6-4838-bb5a-0a57b66d3819",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Alpine Bogs\n",
    "\n",
    "- older format without replicate nr or date, \n",
    "- assuming replicate nr is fixed and corresponds to **second** replicate\n",
    "- 20 samples per visit\n",
    "- 20-50 spp per visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b71d95cf-b05b-4e7b-a303-8957b915bfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: None / Site\n",
      "1 :: Species responses / Subquadrat #\n",
      "2 :: None / Label\n",
      "3 :: Type / Fauna (FA) or flora (FL).\n",
      "4 :: Species code / Species code can be assigned by OEH, or see the reference worksheet.\n",
      "5 :: Common Name / Common name\n",
      "6 :: None / Species (edits in red)\n",
      "7 :: None / CAPS #\n",
      "8 :: None / resprout organ (epicormic,ligno, crown, basal, tuber,rhiz,stol)\n",
      "9 :: None / seedbank type (canopy, soil, transient, other(not canopy)\n",
      "10 :: None / # Live unburnt (no response to fire)\n",
      "11 :: Adults / # resprouted & live\n",
      "12 :: None /  # resprouted & died post-fire\n",
      "13 :: None / # killed in fire\n",
      "14 :: None / #  reproductive\n",
      "15 :: Recruits / # live\n",
      "16 :: None / # died post-fire\n",
      "17 :: None / #  reproductive\n",
      "18 :: None / notes\n"
     ]
    }
   ],
   "source": [
    "filename='UNSW_VegFireResponse_AlpineBogs_reformat_Sep2021.xlsx'\n",
    "worksheet='Floristics'\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae53b240-4a16-4e6f-9916-6532a4a2447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "1634 valid records and 1 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "1634 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_dict={'visit_id':0, 'sample_nr':1, 'fixed_replicate_nr':2,'species':6, 'spcode':4,  'resprout_organ':8, 'seedbank':9,\n",
    "          'adults_unburnt':10,'resprouts_live':11,'resprouts_died':12,'resprouts_kill':13,\n",
    "          'resprouts_reproductive':14,'recruits_live':15, 'recruits_died':16, 'recruits_reproductive':17,\n",
    "                 'notes':18,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf9a53e-1e07-416f-8b66-39709683cc70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Robertson Rainforest\n",
    "\n",
    "- Only one visit to SASrf1 and one to SAS002B\n",
    "- Four samples per visit, 37 - 46 species\n",
    "- Edited file, corrected one entry (SASrf2) to SASrf1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a659d0e-6936-475c-9d1e-dd579dd79bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Updated 14/10/2019 / Entry Order\n",
      "1 :: None / Site Number\n",
      "2 :: None / Replicate\n",
      "3 :: First Date / Date of sighting (dd/mm/yyyy hh:mm:ss).\n",
      "4 :: Last Date / If more than 1 day (dd/mm/yyyy hh:mm:ss).\n",
      "5 :: Sub plot / SubplotID\n",
      "6 :: Type / Fauna (FA) or flora (FL).\n",
      "7 :: Species code / Species code can be assigned by OEH, or see the reference worksheet.\n",
      "8 :: Common Name / None\n",
      "9 :: Scientific Name / None\n",
      "10 :: Cover score / See reference worksheet for definitions\n",
      "11 :: Abundance score / CV18A See reference worksheet for definitions\n",
      "12 :: Stratum / See reference worksheet for definitions\n",
      "13 :: Growth form / See reference worksheet for definitions\n",
      "14 :: Height min / Flora only; height (in metres)\n",
      "15 :: Height max / Flora only; height (in metres)\n",
      "16 :: % Cover actual / None\n",
      "17 :: Recovery organ / None\n",
      "18 :: Seedbank / None\n",
      "19 :: None / Count of unburnt individuals\n",
      "20 :: Abund actual / Count of resprouting individuals.\n",
      "21 :: None /  # resprouted & died post-fire\n",
      "22 :: None / Count of fire-killed individuals\n",
      "23 :: Number reproductive / #  reproductive pre-fire plants\n",
      "24 :: None / Count of live postfire recruits\n",
      "25 :: None / # recruits died post-fire\n",
      "26 :: Number reproductive / #  reproductive recruits\n",
      "27 :: Estimate Code / Accuracy of count. See reference worksheet for definitions.\n",
      "28 :: Source Code / Source of the sighting; automatically populated as '4 - sighting'. Alter if specimen lodged or sighting is questionable (e.g. Anabat). See reference worksheet for definitions.\n",
      "29 :: Specimen Rego / Registration number (if the specimen has been lodged with a herbarium or museum).\n",
      "30 :: Specimen Location / Location of the herbarium or museum (if the specimen has been lodged). See reference worksheet for definitions.\n",
      "31 :: External Key / Observers' own unique reference number.\n",
      "32 :: Notes / Any additional notes about the sighting.\n"
     ]
    }
   ],
   "source": [
    "worksheet='Floristics'\n",
    "filename='RobertsonRF_data_bionet2.xlsx'\n",
    "\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffe884d4-6d7c-482f-b695-acd1bac3f9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "224 valid records and 0 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "224 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "col_dict={'visit_id':1, 'replicate_nr':2, 'date':3,\n",
    "          'sample_nr':5, 'spcode':7, 'species':9,   \n",
    "          'resprout_organ':17, 'seedbank':18,\n",
    "          'adults_unburnt':19,'resprouts_live':20,'resprouts_died':21,'resprouts_kill':22,\n",
    "          'resprouts_reproductive':23,'recruits_live':24, 'recruits_died':25, 'recruits_reproductive':26,\n",
    "                 'notes':32,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab75cae-a0b9-4e8d-bd70-bf029fb2e297",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Newnes\n",
    "\n",
    "- 20 quadrats per visit\n",
    "- Visit information incomplete in many cases (no date, which replicate?)\n",
    "- as few as 4 as many as 37 species per visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c9528ae-a5ca-493a-8497-2f89463152fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: None / Site\n",
      "1 :: Species responses / Quadrat #\n",
      "2 :: None / Label\n",
      "3 :: None / Census#\n",
      "4 :: None / Date\n",
      "5 :: None / Species\n",
      "6 :: None / CAPS #\n",
      "7 :: None / resprout organ (epicormic,ligno, crown, basal, tuber,rhiz,stol)\n",
      "8 :: None / seedbank type (canopy, soil, transient, other(not canopy)\n",
      "9 :: None / # Live unburnt (no response to fire)\n",
      "10 :: Adults / # resprouted & live\n",
      "11 :: None /  # resprouted & died post-fire\n",
      "12 :: None / # killed in fire\n",
      "13 :: None / #  reproductive\n",
      "14 :: Recruits / # live\n",
      "15 :: None / # died post-fire\n",
      "16 :: None / #  reproductive\n",
      "17 :: None / notes\n",
      "18 :: None / total live\n",
      "19 :: None / fire survial\n",
      "20 :: None / seedling/adult\n",
      "21 :: None / notes2\n",
      "22 :: None / live present\n",
      "23 :: None / None\n",
      "24 :: None / None\n",
      "25 :: None / None\n",
      "26 :: None / None\n",
      "27 :: None / None\n",
      "28 :: None / None\n",
      "29 :: None / None\n",
      "30 :: None / None\n"
     ]
    }
   ],
   "source": [
    "filename='Fire response quadrat survey Newnes Nov2020_DK_revised IDs+AllNovData.xlsm'\n",
    "worksheet='Floristics'\n",
    "\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c067b756-27c6-41a4-986f-0bfff0f5d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS1 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for BS2 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW1 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for MW2 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV1 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for HV2 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS1 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for SS2 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE1 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGE2 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW1 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for GGW2 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW1 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CW2 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC1 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for CC2 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW1 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "record for EW2 is incomplete\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "3149 valid records and 2086 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "3149 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "col_dict={'visit_id':0, 'replicate_nr':3, 'date':4,\n",
    "          'sample_nr':1, 'spcode':6, 'species':5,   \n",
    "          'resprout_organ':7, 'seedbank':8,\n",
    "          'adults_unburnt':9,'resprouts_live':10,'resprouts_died':11,'resprouts_kill':12,\n",
    "          'resprouts_reproductive':13,'recruits_live':14, 'recruits_died':15, 'recruits_reproductive':16,\n",
    "                 'notes':17,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fa17b4-18a7-4e9c-afaf-51f9e0159571",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Yatteyattah\n",
    "\n",
    "- sites SCCJB14 and MIL012B not found\n",
    "- no information for SCCJB13 and SCCJB37-Near\n",
    "- 4 visits with one sample per visit, 30 to 78 species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99018a4c-4c08-415b-b027-ec374b6f54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :: Updated 14/10/2019 / Entry Order\n",
      "1 :: None / Site Number\n",
      "2 :: None / Replicate\n",
      "3 :: First Date / Date of sighting (dd/mm/yyyy hh:mm:ss).\n",
      "4 :: Last Date / If more than 1 day (dd/mm/yyyy hh:mm:ss).\n",
      "5 :: Sub plot / SubplotID\n",
      "6 :: Type / Fauna (FA) or flora (FL).\n",
      "7 :: Species code / Species code can be assigned by OEH, or see the reference worksheet.\n",
      "8 :: Common Name / None\n",
      "9 :: Scientific Name / Species\n",
      "10 :: Cover score / None\n",
      "11 :: Abundance score / CV18A See reference worksheet for definitions\n",
      "12 :: Abundance score / CV18A See reference worksheet for definitions\n",
      "13 :: Stratum / See reference worksheet for definitions\n",
      "14 :: Growth form / See reference worksheet for definitions\n",
      "15 :: Height min / Flora only; height (in metres)\n",
      "16 :: Height max / Flora only; height (in metres)\n",
      "17 :: % Cover actual / None\n",
      "18 :: Recovery organ / resprout organ (epicormic,ligno, crown, basal, tuber,rhiz,stol)\n",
      "19 :: Seedbank / seedbank type (canopy, soil, transient, other(not canopy)\n",
      "20 :: Adults / Count of unburnt individuals\n",
      "21 :: Adults / Count of fully scorched & resprouting individuals.\n",
      "22 :: Adults /  # resprouted & died post-fire\n",
      "23 :: Adults / Count of fully scorched & fire-killed individuals\n",
      "24 :: Adults / #  reproductive resprouts\n",
      "25 :: Recruits / Count of postfire recruits\n",
      "26 :: Recruits / # recruits died post-fire\n",
      "27 :: Recruits / #  reproductive recruits\n",
      "28 :: Estimate Code / Accuracy of count. See reference worksheet for definitions.\n",
      "29 :: Source Code / Source of the sighting; automatically populated as '4 - sighting'. Alter if specimen lodged or sighting is questionable (e.g. Anabat). See reference worksheet for definitions.\n",
      "30 :: Specimen Rego / Registration number (if the specimen has been lodged with a herbarium or museum).\n",
      "31 :: Specimen Location / Location of the herbarium or museum (if the specimen has been lodged). See reference worksheet for definitions.\n",
      "32 :: External Key / Observers' own unique reference number.\n",
      "33 :: Notes / Any additional notes about the sighting.\n",
      "34 :: None / Count of partially scorched & resprouting individuals\n"
     ]
    }
   ],
   "source": [
    "worksheet='Floristics'\n",
    "filename='UNSW_VegFireResponse_DataEntry_Yatteyattah all +DK +Milton_revisedfields_Mar2022.xlsx'\n",
    "\n",
    "cols=wbindex[filename][worksheet]\n",
    "for k in range(1,len(cols[0])+1):\n",
    "    print(\"%s :: %s / %s\" % (k-1,cols[0][k-1],cols[1][k-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73d41249-3c7f-4cb8-b27d-7624fd942af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "SCCJB14 not found\n",
      "MIL012B not found\n",
      "0 rows updated\n",
      "Database connection closed.\n",
      "558 valid records and 56 invalid records\n",
      "Connecting to the PostgreSQL database...\n",
      "558 rows updated\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "col_dict={'visit_id':1, 'replicate_nr':2, 'date':3,\n",
    "          'sample_nr':5, 'spcode':7, 'species':9,   \n",
    "          'resprout_organ':18, 'seedbank':19,\n",
    "          'adults_unburnt':20,'resprouts_live':21,'resprouts_died':22,'resprouts_kill':23,\n",
    "          'resprouts_reproductive':24,'recruits_live':25, 'recruits_died':26, 'recruits_reproductive':27,\n",
    "                 'notes':33,'workbook':filename,'worksheet':worksheet}\n",
    "\n",
    "read_and_import_species_data(filepath=inputdir,\n",
    "                             workbook=filename,\n",
    "                             worksheet=worksheet,\n",
    "                             col_dictionary=col_dict,\n",
    "                             valid_seedbank=seedbank_vocab,\n",
    "                             valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebb3fef-1c5b-4404-b3a4-662464afcd70",
   "metadata": {},
   "source": [
    "### Update information from comments\n",
    "\n",
    "Need to add this information into the database:\n",
    "\n",
    "- count of fully scorched & resprouting individuals\n",
    "- count of fully scorched & fire-killed individuals\n",
    "- count of partially scorched & resprouting individuals\n",
    "- count of partially scorched & fire-killed individuals\n",
    "\n",
    "Also identify adults from not adults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545c1bc3-13a5-4c9b-9577-c21d3f2f61aa",
   "metadata": {},
   "source": [
    "Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9e57be6-3c6c-407e-9e2d-cfa89238e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n"
     ]
    }
   ],
   "source": [
    "print('Connecting to the PostgreSQL database...')\n",
    "conn = psycopg2.connect(**params)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d95474-3e21-4a4f-9ed6-cd729aaaf7ef",
   "metadata": {},
   "source": [
    "Check age and scorch vocabularies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1118fe3-9312-4095-8a37-bb75d10a5166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adult', 'juvenile', 'other']\n",
      "['Full canopy scorch', 'Partial scorch', 'Other']\n"
     ]
    }
   ],
   "source": [
    "if 'age_vocab' not in vars():\n",
    "    cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='age_group';\")\n",
    "    age_list = cur.fetchall()\n",
    "    age_vocab = [item for t in age_list for item in t]\n",
    "\n",
    "print(age_vocab)\n",
    "\n",
    "if 'scorch_vocab' not in vars():\n",
    "    cur.execute(\"SELECT enumlabel FROM pg_enum e LEFT JOIN pg_type t ON e.enumtypid=t.oid where typname='scorch_vocabulary';\")\n",
    "    scorch_list = cur.fetchall()\n",
    "    scorch_vocab = [item for t in scorch_list for item in t]\n",
    "\n",
    "print(scorch_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5cc02-6e52-4679-acc5-2d0a2aa58cfd",
   "metadata": {},
   "source": [
    "Filter comments by keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b51a359a-ae19-4ee1-bfd6-49fdaf05c51b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(27324,\n",
       "  'all partially scorched at base, resprouting from both trunk and base'),\n",
       " (27412,\n",
       "  '10 resprouters with dbh <10cm, 7+3 with dbh>10cm (one + two partially burnt), killed plants with dbh 5cm, 9.5cm & 16cm'),\n",
       " (27417, 'adult tree dbh 46 cm, partially burnt')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry = \"\"\"\n",
    "WITH A AS (select record_id,unnest(comments) as note from form.quadrat_samples)\n",
    "SELECT record_id,note FROM A WHERE note ilike '%partial%';\n",
    "\"\"\"\n",
    "cur.execute(qry)\n",
    "\n",
    "records=cur.fetchall()\n",
    "records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db50a985-a429-485f-85e2-e299f6f2ed93",
   "metadata": {},
   "source": [
    "We can run several updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5aa310bd-5f90-4dbe-8564-11336f3c5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "upd = \"\"\"\n",
    "UPDATE form.quadrat_samples SET life_stage='juvenile' where record_id IN\n",
    "(WITH A AS (select record_id,unnest(comments) as note from form.quadrat_samples)\n",
    "SELECT record_id FROM A WHERE note ilike '%juvenil%');\n",
    "\"\"\"\n",
    "\n",
    "upd = \"\"\"\n",
    "UPDATE form.quadrat_samples SET life_stage='adult' where record_id IN\n",
    "(WITH A AS (select record_id,unnest(comments) as note from form.quadrat_samples)\n",
    "SELECT record_id FROM A WHERE note ilike '%adult %');\n",
    "\"\"\"\n",
    "\n",
    "upd = \"\"\"\n",
    "UPDATE form.quadrat_samples SET life_stage='other' where record_id IN\n",
    "(WITH A AS (select record_id,unnest(comments) as note from form.quadrat_samples)\n",
    "SELECT record_id FROM A WHERE note ilike '%sapling%');\n",
    "\"\"\"\n",
    "\n",
    "upd = \"\"\"\n",
    "UPDATE form.quadrat_samples SET scorch='Partial scorch' where record_id IN\n",
    "(WITH A AS (select record_id,unnest(comments) as note from form.quadrat_samples)\n",
    "SELECT record_id FROM A WHERE note ilike '%partial%');\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(upd)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88889f2-e2bc-4069-b2b5-415b10739356",
   "metadata": {},
   "source": [
    "Check how many records are updated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b4a6f87-8a69-4af7-a4bd-61bc31b1bb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(None, None, 10651), (None, 'Partial scorch', 3)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry= \"select life_stage,scorch,count(*) from form.quadrat_samples group by life_stage,scorch;\"\n",
    "cur.execute(qry)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa761324-6840-48d3-a702-754623f3e84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qry=\"\"\"\n",
    "select species,species_code,\n",
    "count(distinct visit_id) as sites,\n",
    "count(distinct (visit_id,visit_date)) as visits,\n",
    "count(distinct (visit_id,visit_date,sample_nr)) as samples,\n",
    "count(distinct record_id) as records\n",
    "from form.quadrat_samples\n",
    "group by species,species_code\n",
    "ORDER BY records DESC;\n",
    "\"\"\"\n",
    "cur.execute(qry)\n",
    "records=cur.fetchall()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f70d2aad-819d-4811-be62-75d5de703dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baumea rubiginosa', 2302, 16, 16, 181, 181),\n",
       " ('Baloskion australe', 10605, 18, 18, 170, 170),\n",
       " ('Baeckea linifolia', 3997, 12, 12, 164, 165),\n",
       " ('Leptospermum grandifolium', 7766, 14, 14, 154, 154),\n",
       " ('Grevillea acanthifolia subsp. acanthifolia', 8875, 19, 19, 141, 141),\n",
       " ('Gonocarpus micranthus', 3243, 13, 13, 120, 121),\n",
       " ('Xyris ustulata', 6325, 13, 13, 121, 121),\n",
       " ('Lepidosperma limicola', 2469, 13, 13, 120, 120),\n",
       " ('Epacris paludosa', 2603, 13, 13, 108, 108)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d5a2d4f-ce18-4e13-8179-3b487ff7e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "conn.commit()\n",
    "cur.close()\n",
    "if conn is not None:\n",
    "    conn.close()\n",
    "    print('Database connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956f4d54-f3c5-4f15-be44-313ccc1490aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Steps for debugging\n",
    "\n",
    "These are some steps to follow to debug errors in the functions."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0ec7ea9-6ae3-4cd2-a6cb-eeac53817daf",
   "metadata": {},
   "source": [
    "quadrats = import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                       create_field_sample_record)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "341d456b-f196-4b62-88e8-addab40e046c",
   "metadata": {},
   "source": [
    "quadrats[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ad52c51-5179-4d52-bbb6-7bb2581efb20",
   "metadata": {},
   "source": [
    "valid_visits = validate_and_update_site_records(quadrats)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "158009bc-0694-47f2-9953-7a1e4f03bf82",
   "metadata": {},
   "source": [
    "for k in valid_visits[1].keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c317de7-3d54-49fa-8d14-a5cc1722c40a",
   "metadata": {},
   "source": [
    "valid_visits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0f9649b-56d4-427f-8029-8d11b014d55f",
   "metadata": {
    "tags": []
   },
   "source": [
    "records=import_records_from_workbook(inputdir, filename, worksheet, col_dict,\n",
    "                                         create_quadrat_sample_record,\n",
    "                                         lookup=valid_visits, valid_seedbank=seedbank_vocab, valid_organ=organ_vocab)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f5bb986-d600-4401-b059-2bc13f001318",
   "metadata": {
    "tags": []
   },
   "source": [
    "print(len(records))\n",
    "record=records[1]\n",
    "record"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be974908-48c6-4968-806e-0ec995187739",
   "metadata": {},
   "source": [
    "valid_records=list()\n",
    "invalid_records=list()\n",
    "for record in records:\n",
    "    if 'visit_date' in record.keys():\n",
    "        p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['visit_date'] == record['visit_date'], valid_visits)\n",
    "        found=list(p)\n",
    "    elif 'replicate_nr' in record.keys():\n",
    "        p=filter(lambda n: n['visit_id'] == record['visit_id'] and  n['replicate_nr'] == record['replicate_nr'], valid_visits)\n",
    "        found=list(p)\n",
    "    else:\n",
    "        found=list()\n",
    "    if (len(found)==1):\n",
    "        valid_records.append(record)\n",
    "    else:\n",
    "        invalid_records.append(record)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e8198d5-4c68-4e1b-8ba7-40c36f2e4a81",
   "metadata": {
    "tags": []
   },
   "source": [
    "minrow=500\n",
    "maxrow=600\n",
    "step = 10\n",
    "\n",
    "for k in range(minrow,maxrow,step):\n",
    "    print(k)\n",
    "    batch_upsert(params,table='form.quadrat_samples',records=valid_records[k:(k+step)],keycol=('visit_id','visit_date','sample_nr'),\n",
    "             idx=None, execute=True)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f36c4f42-d3ec-4d5c-b9b4-17c128e2b5a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "valid_records[k:(k+step)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
